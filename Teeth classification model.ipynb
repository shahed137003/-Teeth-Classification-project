{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# perparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import sklearn\n",
    "import seaborn as sbe\n",
    "import os \n",
    "import math \n",
    "import shutil\n",
    "from glob import glob\n",
    "from numpy import array\n",
    "from imutils import paths\n",
    "from tensorflow.keras import models,layers\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Teeth DataSet\\\\Teeth_Dataset\\\\Training\\\\CaS\\\\a_100_0_1462.jpg'\n",
      "b'Teeth DataSet\\\\Teeth_Dataset\\\\Training\\\\CaS\\\\a_100_0_4424.jpg'\n",
      "b'Teeth DataSet\\\\Teeth_Dataset\\\\Training\\\\CaS\\\\a_100_0_5215.jpg'\n",
      "b'Teeth DataSet\\\\Teeth_Dataset\\\\Training\\\\CaS\\\\a_100_0_5539.jpg'\n",
      "b'Teeth DataSet\\\\Teeth_Dataset\\\\Testing\\\\CaS\\\\a_100.jpg'\n",
      "b'Teeth DataSet\\\\Teeth_Dataset\\\\Testing\\\\CaS\\\\a_101_0_1635.jpg'\n",
      "b'Teeth DataSet\\\\Teeth_Dataset\\\\Testing\\\\CaS\\\\a_101_0_1711.jpg'\n",
      "b'Teeth DataSet\\\\Teeth_Dataset\\\\Testing\\\\CaS\\\\a_101_0_4911.jpg'\n",
      "b'Teeth DataSet\\\\Teeth_Dataset\\\\Validation\\\\CaS\\\\a_100_0_982.jpg'\n",
      "b'Teeth DataSet\\\\Teeth_Dataset\\\\Validation\\\\CaS\\\\a_101_0_2726.jpg'\n",
      "b'Teeth DataSet\\\\Teeth_Dataset\\\\Validation\\\\CaS\\\\a_101_0_5413.jpg'\n",
      "b'Teeth DataSet\\\\Teeth_Dataset\\\\Validation\\\\CaS\\\\a_102_0_5905.jpg'\n"
     ]
    }
   ],
   "source": [
    "training_ds=tf.data.Dataset.list_files(\"Teeth DataSet\\\\Teeth_Dataset\\\\Training\\\\*\\\\*\",shuffle=False)\n",
    "testing_ds=tf.data.Dataset.list_files(\"Teeth DataSet\\\\Teeth_Dataset\\\\Testing\\\\*\\\\*\",shuffle=False)\n",
    "validation_ds=tf.data.Dataset.list_files(\"Teeth DataSet\\\\Teeth_Dataset\\\\Validation\\\\*\\\\*\",shuffle=False)\n",
    "for f in training_ds.take(4):\n",
    "    print(f.numpy())\n",
    "for f in testing_ds.take(4):\n",
    "    print(f.numpy())\n",
    "for f in validation_ds.take(4):\n",
    "    print(f.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3087\n",
      "1028\n",
      "1028\n"
     ]
    }
   ],
   "source": [
    "class_name=[\"CaS\",\"CoS\",\"Gum\",\"MC\",\"OC\",\"OLP\",\"OT\"]\n",
    "training_ds = training_ds.shuffle(200)\n",
    "testing_ds = testing_ds.shuffle(200)\n",
    "validation_ds = validation_ds.shuffle(200)\n",
    "image_train_count=len(training_ds)\n",
    "print(image_train_count)\n",
    "print(len(testing_ds))\n",
    "print(len(validation_ds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#s=\"Teeth DataSet\\\\Teeth_Dataset\\\\Training\\\\MC\"\n",
    "#s.split(\"\\\\\")[-1]\n",
    "def get_label(file_path):\n",
    "    parts = tf.strings.split(file_path, os.path.sep)\n",
    "    return parts[-2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_MapDataset element_spec=TensorSpec(shape=(), dtype=tf.string, name=None)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_ds.map(get_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(file_path):\n",
    "    label=get_label(file_path)\n",
    "    img = tf.io.read_file(file_path)  # Read the image file\n",
    "    img = tf.image.decode_jpeg(img, channels=3)  # Decode as JPEG\n",
    "    img = tf.image.resize(img, [256, 256])  # Resize to 256x256\n",
    "    return img, label  # Return image and label as a tuple\n",
    "\n",
    "\n",
    "#training_ds = training_ds.map(process_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[252., 217., 197.],\n",
       "        [252., 217., 197.],\n",
       "        [252., 217., 197.],\n",
       "        ...,\n",
       "        [245., 244., 249.],\n",
       "        [245., 244., 249.],\n",
       "        [245., 244., 249.]],\n",
       "\n",
       "       [[252., 217., 197.],\n",
       "        [252., 217., 197.],\n",
       "        [252., 217., 197.],\n",
       "        ...,\n",
       "        [245., 244., 249.],\n",
       "        [245., 244., 249.],\n",
       "        [245., 244., 249.]]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img, label = process_image(\"Teeth DataSet\\\\Teeth_Dataset\\\\Training\\\\CaS\\\\a_100_0_1462.jpg\")\n",
    "img.numpy()[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[255. 254. 255.]\n",
      "  [255. 254. 255.]\n",
      "  [255. 254. 255.]\n",
      "  ...\n",
      "  [223. 132. 127.]\n",
      "  [223. 132. 127.]\n",
      "  [223. 132. 127.]]\n",
      "\n",
      " [[255. 255. 255.]\n",
      "  [255. 255. 255.]\n",
      "  [255. 255. 255.]\n",
      "  ...\n",
      "  [223. 132. 127.]\n",
      "  [224. 133. 128.]\n",
      "  [224. 133. 128.]]\n",
      "\n",
      " [[255. 255. 251.]\n",
      "  [255. 255. 251.]\n",
      "  [255. 255. 251.]\n",
      "  ...\n",
      "  [227. 134. 127.]\n",
      "  [227. 134. 127.]\n",
      "  [228. 135. 128.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[255. 255. 255.]\n",
      "  [255. 255. 255.]\n",
      "  [255. 255. 255.]\n",
      "  ...\n",
      "  [252. 141. 157.]\n",
      "  [252. 140. 156.]\n",
      "  [251. 140. 156.]]\n",
      "\n",
      " [[255. 255. 255.]\n",
      "  [255. 255. 255.]\n",
      "  [255. 255. 255.]\n",
      "  ...\n",
      "  [253. 145. 160.]\n",
      "  [254. 143. 159.]\n",
      "  [252. 144. 159.]]\n",
      "\n",
      " [[255. 255. 255.]\n",
      "  [255. 255. 255.]\n",
      "  [255. 255. 255.]\n",
      "  ...\n",
      "  [255. 150. 165.]\n",
      "  [255. 149. 164.]\n",
      "  [255. 149. 164.]]], shape=(256, 256, 3), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[255. 234. 221.]\n",
      "  [255. 235. 221.]\n",
      "  [255. 235. 221.]\n",
      "  ...\n",
      "  [237. 131. 143.]\n",
      "  [237. 131. 143.]\n",
      "  [237. 131. 143.]]\n",
      "\n",
      " [[255. 227. 215.]\n",
      "  [254. 228. 213.]\n",
      "  [253. 230. 216.]\n",
      "  ...\n",
      "  [237. 131. 143.]\n",
      "  [237. 131. 143.]\n",
      "  [237. 131. 143.]]\n",
      "\n",
      " [[252. 223. 209.]\n",
      "  [252. 223. 207.]\n",
      "  [253. 225. 211.]\n",
      "  ...\n",
      "  [237. 131. 143.]\n",
      "  [237. 131. 143.]\n",
      "  [237. 131. 143.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[140. 102.  89.]\n",
      "  [140. 102.  89.]\n",
      "  [140. 102.  89.]\n",
      "  ...\n",
      "  [224.  94. 122.]\n",
      "  [223.  93. 121.]\n",
      "  [223.  93. 121.]]\n",
      "\n",
      " [[140. 102.  89.]\n",
      "  [140. 102.  89.]\n",
      "  [140. 102.  89.]\n",
      "  ...\n",
      "  [226.  96. 124.]\n",
      "  [226.  96. 124.]\n",
      "  [226.  96. 124.]]\n",
      "\n",
      " [[140. 102.  89.]\n",
      "  [140. 102.  89.]\n",
      "  [140. 102.  89.]\n",
      "  ...\n",
      "  [226.  96. 124.]\n",
      "  [226.  96. 124.]\n",
      "  [226.  96. 124.]]], shape=(256, 256, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "training_ds=training_ds.map(process_image)\n",
    "testing_ds=testing_ds.map(process_image)\n",
    "validation_ds=validation_ds.map(process_image)\n",
    "for img,label in training_ds.take(2):\n",
    "    print(img)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** tf.Tensor(\n",
      "[[[177. 105.  91.]\n",
      "  [177. 105.  91.]\n",
      "  [177. 105.  91.]\n",
      "  ...\n",
      "  [161. 124.  97.]\n",
      "  [159. 124.  96.]\n",
      "  [157. 122.  94.]]\n",
      "\n",
      " [[176. 104.  90.]\n",
      "  [176. 104.  90.]\n",
      "  [176. 104.  90.]\n",
      "  ...\n",
      "  [161. 124.  97.]\n",
      "  [158. 123.  95.]\n",
      "  [157. 122.  94.]]\n",
      "\n",
      " [[174. 105.  90.]\n",
      "  [174. 105.  90.]\n",
      "  [176. 104.  90.]\n",
      "  ...\n",
      "  [161. 124.  97.]\n",
      "  [158. 123.  95.]\n",
      "  [157. 122.  94.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[195. 113. 102.]\n",
      "  [207. 125. 114.]\n",
      "  [211. 129. 117.]\n",
      "  ...\n",
      "  [190. 121.  90.]\n",
      "  [189. 120.  89.]\n",
      "  [188. 119.  88.]]\n",
      "\n",
      " [[201. 119. 108.]\n",
      "  [208. 126. 115.]\n",
      "  [208. 126. 114.]\n",
      "  ...\n",
      "  [193. 124.  93.]\n",
      "  [192. 123.  92.]\n",
      "  [191. 122.  91.]]\n",
      "\n",
      " [[205. 123. 112.]\n",
      "  [209. 127. 116.]\n",
      "  [205. 123. 111.]\n",
      "  ...\n",
      "  [195. 126.  95.]\n",
      "  [194. 125.  94.]\n",
      "  [194. 125.  94.]]], shape=(256, 256, 3), dtype=float32)\n",
      "**** tf.Tensor(b'CaS', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "for image, label in training_ds.take(1):\n",
    "    print(\"****\",image)\n",
    "    print(\"****\",label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(image, label):\n",
    "    return image/255, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_ds=training_ds.map(scale)\n",
    "testing_ds=testing_ds.map(scale)\n",
    "validation_ds=validation_ds.map(scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3087, 256, 256, 3) (3087,)\n"
     ]
    }
   ],
   "source": [
    "# Extracting images (x_train) and labels (y_train) as numpy arrays\n",
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "for img, label in training_ds.as_numpy_iterator():\n",
    "    x_train.append(img)\n",
    "    y_train.append(label)\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "print(x_train.shape, y_train.shape)  # Check the shapes of the data\n",
    "#print(type(y_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1028, 256, 256, 3) (1028,)\n"
     ]
    }
   ],
   "source": [
    "# Extracting images (x_train) and labels (y_train) as numpy arrays\n",
    "x_test = []\n",
    "y_test = []\n",
    "\n",
    "for img, label in testing_ds.as_numpy_iterator():\n",
    "    x_test.append(img)\n",
    "    y_test.append(label)\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "x_test = np.array(x_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "print(x_test.shape, y_test.shape)  # Check the shapes of the data\n",
    "#print(type(y_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1028, 256, 256, 3) (1028,)\n"
     ]
    }
   ],
   "source": [
    "# Extracting images (x_train) and labels (y_train) as numpy arrays\n",
    "x_val = []\n",
    "y_val = []\n",
    "\n",
    "for img, label in validation_ds.as_numpy_iterator():\n",
    "    x_val.append(img)\n",
    "    y_val.append(label)\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "x_val = np.array(x_val)\n",
    "y_val = np.array(y_val)\n",
    "\n",
    "print(x_val.shape, y_val.shape)  # Check the shapes of the data\n",
    "#print(type(y_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_val = x_val.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 6 6 6]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Initialize the LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit the encoder and transform string labels to integer labels\n",
    "y_train = label_encoder.fit_transform(y_train)\n",
    "y_test = label_encoder.fit_transform(y_test)\n",
    "y_val = label_encoder.fit_transform(y_val)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3087, 256, 256, 3)\n",
      "(3087,)\n",
      "[array([0, 0, 0, ..., 6, 6, 6], dtype=int64)]\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "y_train = y_train.reshape(-1,)\n",
    "print([y_train])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here we prepare the data to be used in the modeling process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shahd\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "cnn = models.Sequential([\n",
    "    layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(256, 256, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(7, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.compile(optimizer='adam',\n",
    "            loss='sparse_categorical_crossentropy',\n",
    "            metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">254</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">254</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">125</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">125</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">246016</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │    <span style=\"color: #00af00; text-decoration-color: #00af00\">15,745,088</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">455</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m254\u001b[0m, \u001b[38;5;34m254\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m125\u001b[0m, \u001b[38;5;34m125\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m62\u001b[0m, \u001b[38;5;34m62\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m246016\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │    \u001b[38;5;34m15,745,088\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)              │           \u001b[38;5;34m455\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">47,294,807</span> (180.42 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m47,294,807\u001b[0m (180.42 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">15,764,935</span> (60.14 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m15,764,935\u001b[0m (60.14 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">31,529,872</span> (120.28 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m31,529,872\u001b[0m (120.28 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 409ms/step - accuracy: 0.1934 - loss: 3.5111\n",
      "Epoch 2/10\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 406ms/step - accuracy: 0.3638 - loss: 1.6998\n",
      "Epoch 3/10\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 399ms/step - accuracy: 0.5284 - loss: 1.3989\n",
      "Epoch 4/10\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 390ms/step - accuracy: 0.7733 - loss: 0.6997\n",
      "Epoch 5/10\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 388ms/step - accuracy: 0.9468 - loss: 0.2330\n",
      "Epoch 6/10\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 507ms/step - accuracy: 0.9899 - loss: 0.0709\n",
      "Epoch 7/10\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 504ms/step - accuracy: 0.9971 - loss: 0.0156\n",
      "Epoch 8/10\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 424ms/step - accuracy: 0.9993 - loss: 0.0052\n",
      "Epoch 9/10\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 548ms/step - accuracy: 1.0000 - loss: 0.0016\n",
      "Epoch 10/10\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 414ms/step - accuracy: 1.0000 - loss: 9.3422e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1db774e4ca0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.fit(x_train, y_train, epochs=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
